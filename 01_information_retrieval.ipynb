{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f425f36f",
   "metadata": {},
   "source": [
    "# Information Retrieval / Suche mit Python\n",
    "\n",
    "### 1) Keyword-basierte Suche · 2) Gewichtete Suche mit Whoosh · 3) Semantische Suche mit Embeddings\n",
    "\n",
    "In dieser Übung lernen Sie verschiedene Möglichkeiten kennen, eine Suche in einem kleinen Beispielkorpus zu implementieren - von einem einfachen keyword-basierten Ansatz über die eine gewichtete Suche mit TF-IDF bis hin zu semantischer Suche mit Embeddings. \n",
    "\n",
    "\n",
    "**Vorbereitung:**\n",
    "1. `venv` aktivieren!\n",
    "2. Benötigte Libraries installieren: `pip install whoosh sentence-transformers numpy`\n",
    "3. Neu installierte Libraries zu `requirements.txt` hinzufügen: `pip freeze > requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83434c8",
   "metadata": {},
   "source": [
    "## Beispielkorpus erzeugen\n",
    "\n",
    "Wir arbeiten mit einer erweiterten Version des FAQ-Korpus aus der Python-Einführung. \n",
    "\n",
    "Um diesen zu erzeugen habe ich den ursprünglichen Korpus mit Hilfe eines LLMs [*augmentiert*](https://www.datacamp.com/tutorial/complete-guide-data-augmentation), d.h. Variationen der Beispieldokumente erzeugt, um die Datenbasis zu erweitern:"
   ]
  },
  {
   "cell_type": "code",
   "id": "9a76a702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T18:17:28.416820Z",
     "start_time": "2025-11-09T18:17:28.413539Z"
    }
   },
   "source": [
    "documents = [\n",
    "    'Wie kann ich mein Passwort Passwort zurücksetzen?',\n",
    "    'Wie ändere ich mein Passwort?',\n",
    "    'Passwort vergessen - wie kann ich es zurücksetzen?',\n",
    "    'Wie kann ich mein Login-Passwort erneuern?',\n",
    "    'Wo finde ich meine Bestellhistorie?',\n",
    "    'Wie kann ich meine bisherigen Bestellungen einsehen?',\n",
    "    'Wo sehe ich meine vergangenen Bestellungen?',\n",
    "    'Wo kann ich meine Bestellungen überprüfen?',\n",
    "    'Bestellhistorie abrufen wie geht das?',\n",
    "    'Wie kann ich meine Lieferadresse ändern?',\n",
    "    'Lieferadresse aktualisieren wie geht das?',\n",
    "    'Wie ändere ich meine Versandadresse?',\n",
    "    'Kann ich meine Adresse nachträglich ändern?',\n",
    "    'Adresse für Lieferung ändern möglich?',\n",
    "    'Wie kontaktiere ich den Kundendienst?',\n",
    "    'Wie erreiche ich den Support?',\n",
    "    'Kundendienst kontaktieren wie?',\n",
    "    'Wo kann ich den Kundenservice erreichen?',\n",
    "    'Wie bekomme ich Hilfe vom Support-Team?',\n",
    "    'Welche Zahlungsmethoden werden akzeptiert?',\n",
    "    'Welche Bezahlmöglichkeiten gibt es?',\n",
    "    'Wie kann ich bezahlen?',\n",
    "    'Akzeptierte Zahlungsmethoden - Übersicht',\n",
    "    'Welche Zahlungsarten stehen zur Verfügung?',\n",
    "    'Wie kann ich meine Bestellung stornieren?',\n",
    "    'Bestellung rückgängig machen wie?',\n",
    "    'Wie annulliere ich eine Bestellung?',\n",
    "    'Kann ich meine Bestellung noch stornieren?',\n",
    "    'Stornierung einer Bestellung Anleitung',\n",
    "    'Wie lange dauert der Versand?',\n",
    "    'Versanddauer - wie lange dauert es?',\n",
    "    'Wann wird meine Bestellung geliefert?',\n",
    "    'Lieferzeitraum - wie lang ist er?',\n",
    "    'Wie schnell kommt meine Bestellung an?',\n",
    "    'Kann ich Artikel nach der Bestellung noch ändern?',\n",
    "    'Kann ich meine Bestellung nachträglich bearbeiten?',\n",
    "    'Artikel in einer bereits getätigten Bestellung ändern - geht das?',\n",
    "    'Bestellung nachträglich ändern - möglich?',\n",
    "    'Kann ich Produkte nach der Bestellung austauschen?'\n",
    "]\n",
    "print(f'{len(documents)} documents loaded.')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 documents loaded.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "587700ec",
   "metadata": {},
   "source": [
    "### 1. Einen einfachen **Invertierten Index** erzeugen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f498b",
   "metadata": {},
   "source": [
    "Bei dieser Aufgabe geht es darum, die Dokumente aus dem Korpus so zu organisieren, dass Sie schnell Dokumente finden können, die ein gesuchtes Wort enthalten.\n",
    "\n",
    "#### 1. Erstellen Sie einen invertierten Index:\n",
    "\n",
    "- Erzeugen Sie ein dictionary, in dem die keys Wörter und die values Listen mit den IDs der Dokumente sind, in denen das jeweilige Wort vorkommt.\n",
    "\n",
    "- Preprocessing-Vorgaben: Schreiben Sie alle Wörter in Kleinbuchstaben und entfernen Sie Satzzeichen. \n",
    "\n",
    "#### 2. Schreiben Sie eine Funktion, um in Ihrem invertierten Index nach einem Wort zu suchen:\n",
    "\n",
    "- Die Funktion soll eine Liste mit allen IDs der Dokumente zurückgeben, die das gesuchte Wort enthalten.\n",
    "\n",
    "- Testen Sie die Funktion, indem Sie jedes passende Dokument und seine ID mit `print()` ausgeben.\n",
    "\n",
    "#### Beispiel-Ausgabe: \n",
    "\n",
    "```\n",
    "[[0, 'Wie kann ich mein Passwort Passwort zurücksetzen?'],\n",
    " [0, 'Wie kann ich mein Passwort Passwort zurücksetzen?'],\n",
    " [1, 'Wie ändere ich mein Passwort?'],\n",
    " [2, 'Passwort vergessen - wie kann ich es zurücksetzen?']]\n",
    "```\n",
    "\n",
    "#### Hinweise:\n",
    "- Nutzen Sie `.split()` für die Tokenisierung.\n",
    "\n",
    "- Nutzen Sie `.lower()`,  `.strip('')` und ggf. `.replace()` für das Preprocessing.\n",
    "\n",
    "- Mit `enumerate(documents)` können Sie sowohl auf das jeweilige Dokument als auch auf den Index zugreifen: \n",
    "\n",
    "- Beachten Sie, dass ein Wort in mehreren Dokumenten vorkommen kann - speichern Sie deshalb pro Wort eine Liste mit Document-IDs."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f386cf87db5635c3"
  },
  {
   "cell_type": "code",
   "id": "d61e72b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T18:16:54.315472Z",
     "start_time": "2025-11-09T18:16:54.313308Z"
    }
   },
   "source": [
    "# 1. Invertierten Index erzeugen\n",
    "# a) Funktion für Preprocessing\n",
    "#funktion erwartet, dass die variable text ein string ist\n",
    "# der pfeil bedeutet, wir geben am ende der funktion eine list die strings enthält zurück\n",
    "def preprocessing (text: str) -> list[str]:\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"?\", \" \").replace(\"-\", \" \").strip()\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "\n",
    "print(preprocessing(\"Passwort vergessen - wie kann ich es zurücksetzen?\"))\n",
    "\n",
    "\n",
    "# Testen"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['passwort', 'vergessen', 'wie', 'kann', 'ich', 'es', 'zurücksetzen']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "2b30661e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T18:19:41.056238Z",
     "start_time": "2025-11-09T18:19:41.048883Z"
    }
   },
   "source": [
    "# b) Invertierten Index bauen\n",
    "#nimmt eine liste mit strings entgegen\n",
    "#gibt ein dictionary (key/value) zurück\n",
    "def build_inverted_index(document_input: list[str]) -> dict:\n",
    "    index = {}  #erstellt leeres dictionary\n",
    "    for i, doc in enumerate(document_input):\n",
    "        #enumerate ist ein counter, der i hoch zählt und pro i ein doc zuweist\n",
    "        tokens = preprocessing(doc)\n",
    "        for token in tokens: #für alle einzelne wörter in tokens\n",
    "            if token in index:\n",
    "                index[token].append(i)\n",
    "            else:\n",
    "                index[token] = [i]\n",
    "    return index\n",
    "\n",
    "# Testen\n",
    "\n",
    "inverted_index = build_inverted_index(documents)\n",
    "print(len(inverted_index), \"Wörter im Index\")\n",
    "print(inverted_index.get('passwort', [])) #test wo passwort vorkommt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 Wörter im Index\n",
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "da59fdc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T10:29:23.200688Z",
     "start_time": "2025-11-05T10:29:23.198007Z"
    }
   },
   "source": [
    "# 2. Such-Funktion\n",
    "#Die Funktion soll eine Liste mit allen IDs der Dokumente zurückgeben,\n",
    "# die das gesuchte Wort enthalten.\n",
    "\n",
    "def search_specific_word (word: str, inverted_index: dict[str, list[int]]) -> list[int]:\n",
    "    return inverted_index.get(word, [])"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "3eefec46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:43:20.899373Z",
     "start_time": "2025-11-05T12:43:20.892833Z"
    }
   },
   "source": [
    "# Testen\n",
    "search_specific_word(\"passwort\", inverted_index)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "56695fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T13:02:05.216519Z",
     "start_time": "2025-11-10T13:02:05.209903Z"
    }
   },
   "source": [
    "# Bonus: Verbesserte Suche mit Ranking\n",
    "\n",
    "def ranking_of_inverted_index (word: str, documents: list[str], inverted_index: dict[str, list[int]]) -> list[list]:\n",
    "    doc_ids = inverted_index.get(word, [])\n",
    "    results = []\n",
    "    for i in doc_ids:\n",
    "        count = preprocessing(documents[i]).count(word)\n",
    "        results.append([i, documents[i], count])\n",
    "        results = sorted(results, key=lambda x: x[2], reverse=False)\n",
    "#sortiert die liste restults nach dem element x, welches das dritte ist, also unter index 2 zu finden ist\n",
    "#reverse gibt an ob auf- oder absteigend\n",
    "        return results"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc6610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 'Wie kann ich mein Passwort Passwort zurücksetzen?', 2],\n",
       " [1, 'Wie ändere ich mein Passwort?', 1],\n",
       " [2, 'Passwort vergessen - wie kann ich es zurücksetzen?', 1]]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7412da79",
   "metadata": {},
   "source": [
    "## 2. **Gewichtete Suche** mit Whoosh\n",
    "\n",
    "Bei dieser Aufgabe lernen Sie die IR-Library `Whoosh` kennen. \n",
    "\n",
    "Wir bauen mit `Whoosh` einen Index, fügen Dokumente hinzu und führen dann eine Suche aus. Whoosh ist eine reine Python-Such-Bibliothek, die ermöglicht, Volltextsuche auf Textdateien zu implementieren.\n",
    "\n",
    "Das Schema erklärt, welche Felder in den Dokumenten enthalten sind und wie die Dokumente aussehen, sodass Whoosh weiß, wie es die Felder durchsuchen und speichern kann.\n",
    "\n",
    "`Whoosh` ermöglicht es uns, eine gewichtete Suche zu machen, z.B. mit `TF-IDF` oder `BM25`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.index import create_in\n",
    "from whoosh.fields import Schema, TEXT, ID\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh import scoring  # for choosing the ranking algorithm\n",
    "import os, shutil\n",
    "\n",
    "# Schema für den Index definieren: Wie ist ein einzelnes Dokument in meinem Suchindex aufgebaut? Ich antworte in der Methode: jedes Dokument hat 2 Felder: id und content\n",
    "schema = Schema(\n",
    "    id=ID(stored=True),       # Feld erhält einen eindeutigen Index, wird gespeichert\n",
    "    content=TEXT(stored=True)  # durchsuchbarer Text, tokenisiert, aber original wird stored\n",
    ")\n",
    "\n",
    "# Verzeichnis für den Index vorbereiten\n",
    "if os.path.exists('indexdir'):   #lokaler ordner für das speichern aller indexdaten, indem whoosh sie speichert\n",
    "    shutil.rmtree('indexdir')\n",
    "os.mkdir('indexdir')\n",
    "\n",
    "# Index erzeugen und Dokumente hinzufügen\n",
    "ix = create_in('indexdir', schema)\n",
    "writer = ix.writer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f15ab3c",
   "metadata": {},
   "source": [
    "**2.1 Aufgabe:** Vervollständigen Sie den folgenden Code, indem Sie die `???` ersetzen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66138703",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(documents):\n",
    "    writer.add_document(id=str('???'), content='???') \n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7f787",
   "metadata": {},
   "source": [
    "**2.2.** Aufgabe: \n",
    "\n",
    "- Testen Sie die folgende Suchfunktion mit verschiedenen Queries. \n",
    "- Verändern Sie das Limit der angezeigten Suchergebnisse. \n",
    "- Bei Bedarf können Sie auch den Beispielkorpus `documents` verändern. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b68d28ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Ranking:\n",
      "Score: 5.137 | Doc 29: Wie lange dauert der Versand?\n",
      "Score: 5.137 | Doc 30: Versanddauer - wie lange dauert es?\n"
     ]
    }
   ],
   "source": [
    "# Durchsuchen des Index mit TF-IDF Gewichtung -> seltene Wörter haben mehr Gewicht\n",
    "query = 'wie lange' \n",
    "\n",
    "with ix.searcher(weighting=scoring.TF_IDF()) as searcher:  \n",
    "    query_str = query\n",
    "    parser = QueryParser('content', ix.schema)\n",
    "    query = parser.parse(query_str)\n",
    "\n",
    "    # Index durchsuchen, top n Treffer anzeigen\n",
    "    top_n = 5\n",
    "    results = searcher.search(query, limit=top_n)\n",
    "\n",
    "    print(\"TF-IDF Ranking:\")\n",
    "    for hit in results:\n",
    "        print(f\"Score: {hit.score:.3f} | Doc {hit['id']}: {hit['content']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c65521",
   "metadata": {},
   "source": [
    "**Aufgabe 2.3:** \n",
    "\n",
    "- Passen Sie den Code so an, dass `BM25F` für die Gewichtung verwendet wird.\n",
    "- Probieren Sie die Suche erneut aus und schauen Sie, ob sich etwas verändert. \n",
    "- Passen Sie auch hier ggf. den Beispielkorpus an, z.B. indem Sie längere Dokumente hinzufügen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475213c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösung: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b26ae55",
   "metadata": {},
   "source": [
    "**Aufgabe 2.4:**\n",
    "\n",
    "- Vergleichen Sie die Suchergebnisse der manuellen Suche mit den Ergebnissen der gewichteten Suche. \n",
    "- Gibt es Unterschiede zwischen den Ergebnissen basierend auf TF-IDF vs. BM25F?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e979c",
   "metadata": {},
   "source": [
    "## 3. **Semantische Suche** mit Sentence Transformers\n",
    "\n",
    "- In dieser Demo nutzen Sie die `Sentence Transformers` Library, um Embeddings für den Beispielkorpus zu erzeugen. \n",
    "- Diese Embeddings nutzen Sie, um semantisch ähnliche Dokumente zu Ihrer Suche zu finden, mit Hilfe der Kosinus-Ähnlichkeit. "
   ]
  },
  {
   "cell_type": "code",
   "id": "497fc8e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T13:51:28.257970Z",
     "start_time": "2025-11-05T13:51:10.482778Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Laden eines vortrainierten Modells\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Embeddings für die Dokumente erzeugen\n",
    "doc_embeddings = model.encode(documents, convert_to_tensor=True)"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msentence_transformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SentenceTransformer, util\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# Laden eines vortrainierten Modells\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m model = \u001B[43mSentenceTransformer\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43msentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# Embeddings für die Dokumente erzeugen\u001B[39;00m\n\u001B[32m      7\u001B[39m doc_embeddings = model.encode(documents, convert_to_tensor=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/sentence_transformers/SentenceTransformer.py:327\u001B[39m, in \u001B[36mSentenceTransformer.__init__\u001B[39m\u001B[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001B[39m\n\u001B[32m    309\u001B[39m has_modules = is_sentence_transformer_model(\n\u001B[32m    310\u001B[39m     model_name_or_path,\n\u001B[32m    311\u001B[39m     token,\n\u001B[32m   (...)\u001B[39m\u001B[32m    314\u001B[39m     local_files_only=local_files_only,\n\u001B[32m    315\u001B[39m )\n\u001B[32m    316\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    317\u001B[39m     has_modules\n\u001B[32m    318\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._get_model_type(\n\u001B[32m   (...)\u001B[39m\u001B[32m    325\u001B[39m     == \u001B[38;5;28mself\u001B[39m._model_config[\u001B[33m\"\u001B[39m\u001B[33mmodel_type\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    326\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m327\u001B[39m     modules, \u001B[38;5;28mself\u001B[39m.module_kwargs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_load_sbert_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    328\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    329\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    330\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_folder\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    331\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    332\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    333\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    334\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    335\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    336\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    337\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    338\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    339\u001B[39m     modules = \u001B[38;5;28mself\u001B[39m._load_auto_model(\n\u001B[32m    340\u001B[39m         model_name_or_path,\n\u001B[32m    341\u001B[39m         token=token,\n\u001B[32m   (...)\u001B[39m\u001B[32m    349\u001B[39m         has_modules=has_modules,\n\u001B[32m    350\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/sentence_transformers/SentenceTransformer.py:2305\u001B[39m, in \u001B[36mSentenceTransformer._load_sbert_model\u001B[39m\u001B[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001B[39m\n\u001B[32m   2300\u001B[39m         module = module_class.load(local_path)\n\u001B[32m   2302\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2303\u001B[39m     \u001B[38;5;66;03m# Newer modules that support the new loading method are loaded with the new style\u001B[39;00m\n\u001B[32m   2304\u001B[39m     \u001B[38;5;66;03m# i.e. with many keyword arguments that can optionally be used by the modules\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2305\u001B[39m     module = \u001B[43mmodule_class\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2306\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2307\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Loading-specific keyword arguments\u001B[39;49;00m\n\u001B[32m   2308\u001B[39m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodule_config\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpath\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2309\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2310\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_folder\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2311\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2312\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2313\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Module-specific keyword arguments\u001B[39;49;00m\n\u001B[32m   2314\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2315\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2316\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2317\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2318\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2319\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2321\u001B[39m modules[module_config[\u001B[33m\"\u001B[39m\u001B[33mname\u001B[39m\u001B[33m\"\u001B[39m]] = module\n\u001B[32m   2322\u001B[39m module_kwargs[module_config[\u001B[33m\"\u001B[39m\u001B[33mname\u001B[39m\u001B[33m\"\u001B[39m]] = module_config.get(\u001B[33m\"\u001B[39m\u001B[33mkwargs\u001B[39m\u001B[33m\"\u001B[39m, [])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/sentence_transformers/models/Transformer.py:365\u001B[39m, in \u001B[36mTransformer.load\u001B[39m\u001B[34m(cls, model_name_or_path, subfolder, token, cache_folder, revision, local_files_only, trust_remote_code, model_kwargs, tokenizer_kwargs, config_kwargs, backend, **kwargs)\u001B[39m\n\u001B[32m    334\u001B[39m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[32m    335\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload\u001B[39m(\n\u001B[32m    336\u001B[39m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    350\u001B[39m     **kwargs,\n\u001B[32m    351\u001B[39m ) -> Self:\n\u001B[32m    352\u001B[39m     init_kwargs = \u001B[38;5;28mcls\u001B[39m._load_init_kwargs(\n\u001B[32m    353\u001B[39m         model_name_or_path=model_name_or_path,\n\u001B[32m    354\u001B[39m         subfolder=subfolder,\n\u001B[32m   (...)\u001B[39m\u001B[32m    363\u001B[39m         backend=backend,\n\u001B[32m    364\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m365\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43minit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/sentence_transformers/models/Transformer.py:88\u001B[39m, in \u001B[36mTransformer.__init__\u001B[39m\u001B[34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001B[39m\n\u001B[32m     85\u001B[39m     config_args = {}\n\u001B[32m     87\u001B[39m config, is_peft_model = \u001B[38;5;28mself\u001B[39m._load_config(model_name_or_path, cache_dir, backend, config_args)\n\u001B[32m---> \u001B[39m\u001B[32m88\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_load_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_peft_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     90\u001B[39m \u001B[38;5;66;03m# Get the signature of the auto_model's forward method to pass only the expected arguments from `features`,\u001B[39;00m\n\u001B[32m     91\u001B[39m \u001B[38;5;66;03m# plus some common values like \"input_ids\", \"attention_mask\", etc.\u001B[39;00m\n\u001B[32m     92\u001B[39m model_forward_params = \u001B[38;5;28mlist\u001B[39m(inspect.signature(\u001B[38;5;28mself\u001B[39m.auto_model.forward).parameters)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/sentence_transformers/models/Transformer.py:196\u001B[39m, in \u001B[36mTransformer._load_model\u001B[39m\u001B[34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001B[39m\n\u001B[32m    194\u001B[39m         \u001B[38;5;28mself\u001B[39m._load_mt5_model(model_name_or_path, config, cache_dir, **model_args)\n\u001B[32m    195\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m196\u001B[39m         \u001B[38;5;28mself\u001B[39m.auto_model = \u001B[43mAutoModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    197\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\n\u001B[32m    198\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    199\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m backend == \u001B[33m\"\u001B[39m\u001B[33monnx\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    200\u001B[39m     \u001B[38;5;28mself\u001B[39m.auto_model = load_onnx_model(\n\u001B[32m    201\u001B[39m         model_name_or_path=model_name_or_path,\n\u001B[32m    202\u001B[39m         config=config,\n\u001B[32m    203\u001B[39m         task_name=\u001B[33m\"\u001B[39m\u001B[33mfeature-extraction\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    204\u001B[39m         **model_args,\n\u001B[32m    205\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/transformers/models/auto/auto_factory.py:604\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    602\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m model_class.config_class == config.sub_configs.get(\u001B[33m\"\u001B[39m\u001B[33mtext_config\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    603\u001B[39m         config = config.get_text_config()\n\u001B[32m--> \u001B[39m\u001B[32m604\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    605\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    606\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    607\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    608\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig.\u001B[34m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    609\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m.join(c.\u001B[34m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m._model_mapping)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    610\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/transformers/modeling_utils.py:277\u001B[39m, in \u001B[36mrestore_default_dtype.<locals>._wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    275\u001B[39m old_dtype = torch.get_default_dtype()\n\u001B[32m    276\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m277\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    279\u001B[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/transformers/modeling_utils.py:4900\u001B[39m, in \u001B[36mPreTrainedModel.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[39m\n\u001B[32m   4890\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   4891\u001B[39m     gguf_file\n\u001B[32m   4892\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m device_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4893\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m ((\u001B[38;5;28misinstance\u001B[39m(device_map, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map.values()) \u001B[38;5;129;01mor\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map)\n\u001B[32m   4894\u001B[39m ):\n\u001B[32m   4895\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   4896\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4897\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mloaded from GGUF files.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4898\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m4900\u001B[39m checkpoint_files, sharded_metadata = \u001B[43m_get_resolved_checkpoint_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4901\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4902\u001B[39m \u001B[43m    \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4903\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4904\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgguf_file\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgguf_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4905\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4906\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4907\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4908\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4909\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4910\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4911\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4912\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4913\u001B[39m \u001B[43m    \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4914\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4915\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4916\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_remote_code\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_auto_class\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   4917\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtransformers_explicit_filename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtransformers_explicit_filename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4918\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4920\u001B[39m is_sharded = sharded_metadata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4921\u001B[39m is_quantized = hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/transformers/modeling_utils.py:1037\u001B[39m, in \u001B[36m_get_resolved_checkpoint_files\u001B[39m\u001B[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001B[39m\n\u001B[32m   1022\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1023\u001B[39m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[32m   1024\u001B[39m     cached_file_kwargs = {\n\u001B[32m   1025\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mcache_dir\u001B[39m\u001B[33m\"\u001B[39m: cache_dir,\n\u001B[32m   1026\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mforce_download\u001B[39m\u001B[33m\"\u001B[39m: force_download,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1035\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m_commit_hash\u001B[39m\u001B[33m\"\u001B[39m: commit_hash,\n\u001B[32m   1036\u001B[39m     }\n\u001B[32m-> \u001B[39m\u001B[32m1037\u001B[39m     resolved_archive_file = \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcached_file_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1039\u001B[39m     \u001B[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001B[39;00m\n\u001B[32m   1040\u001B[39m     \u001B[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001B[39;00m\n\u001B[32m   1041\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m resolved_archive_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m filename == _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001B[32m   1042\u001B[39m         \u001B[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/transformers/utils/hub.py:322\u001B[39m, in \u001B[36mcached_file\u001B[39m\u001B[34m(path_or_repo_id, filename, **kwargs)\u001B[39m\n\u001B[32m    264\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcached_file\u001B[39m(\n\u001B[32m    265\u001B[39m     path_or_repo_id: Union[\u001B[38;5;28mstr\u001B[39m, os.PathLike],\n\u001B[32m    266\u001B[39m     filename: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m    267\u001B[39m     **kwargs,\n\u001B[32m    268\u001B[39m ) -> Optional[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[32m    269\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    270\u001B[39m \u001B[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001B[39;00m\n\u001B[32m    271\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    320\u001B[39m \u001B[33;03m    ```\u001B[39;00m\n\u001B[32m    321\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     file = \u001B[43mcached_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    323\u001B[39m     file = file[\u001B[32m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m file\n\u001B[32m    324\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m file\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/transformers/utils/hub.py:479\u001B[39m, in \u001B[36mcached_files\u001B[39m\u001B[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[39m\n\u001B[32m    476\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    477\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(full_filenames) == \u001B[32m1\u001B[39m:\n\u001B[32m    478\u001B[39m         \u001B[38;5;66;03m# This is slightly better for only 1 file\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m479\u001B[39m         \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    480\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    481\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    482\u001B[39m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    485\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    486\u001B[39m \u001B[43m            \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    487\u001B[39m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    488\u001B[39m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    489\u001B[39m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    490\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    491\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    492\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    493\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    494\u001B[39m         snapshot_download(\n\u001B[32m    495\u001B[39m             path_or_repo_id,\n\u001B[32m    496\u001B[39m             allow_patterns=full_filenames,\n\u001B[32m   (...)\u001B[39m\u001B[32m    505\u001B[39m             local_files_only=local_files_only,\n\u001B[32m    506\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/huggingface_hub/utils/_validators.py:114\u001B[39m, in \u001B[36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[32m    112\u001B[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001B[34m__name__\u001B[39m, has_token=has_token, kwargs=kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/huggingface_hub/file_download.py:1007\u001B[39m, in \u001B[36mhf_hub_download\u001B[39m\u001B[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001B[39m\n\u001B[32m    987\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _hf_hub_download_to_local_dir(\n\u001B[32m    988\u001B[39m         \u001B[38;5;66;03m# Destination\u001B[39;00m\n\u001B[32m    989\u001B[39m         local_dir=local_dir,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1004\u001B[39m         local_files_only=local_files_only,\n\u001B[32m   1005\u001B[39m     )\n\u001B[32m   1006\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1007\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_hf_hub_download_to_cache_dir\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1008\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Destination\u001B[39;49;00m\n\u001B[32m   1009\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1010\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# File info\u001B[39;49;00m\n\u001B[32m   1011\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1012\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1013\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1014\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1015\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# HTTP info\u001B[39;49;00m\n\u001B[32m   1016\u001B[39m \u001B[43m        \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1017\u001B[39m \u001B[43m        \u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1018\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhf_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1019\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1020\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1021\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Additional options\u001B[39;49;00m\n\u001B[32m   1022\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1023\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1024\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/huggingface_hub/file_download.py:1168\u001B[39m, in \u001B[36m_hf_hub_download_to_cache_dir\u001B[39m\u001B[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001B[39m\n\u001B[32m   1165\u001B[39m \u001B[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001B[39;00m\n\u001B[32m   1167\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m WeakFileLock(lock_path):\n\u001B[32m-> \u001B[39m\u001B[32m1168\u001B[39m     \u001B[43m_download_to_tmp_and_move\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1169\u001B[39m \u001B[43m        \u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob_path\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m.incomplete\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1170\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdestination_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1171\u001B[39m \u001B[43m        \u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1172\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1173\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1174\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1175\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1176\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1177\u001B[39m \u001B[43m        \u001B[49m\u001B[43metag\u001B[49m\u001B[43m=\u001B[49m\u001B[43metag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1178\u001B[39m \u001B[43m        \u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1179\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1180\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os.path.exists(pointer_path):\n\u001B[32m   1181\u001B[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/huggingface_hub/file_download.py:1720\u001B[39m, in \u001B[36m_download_to_tmp_and_move\u001B[39m\u001B[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001B[39m\n\u001B[32m   1718\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m xet_file_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m is_xet_available():\n\u001B[32m   1719\u001B[39m     logger.debug(\u001B[33m\"\u001B[39m\u001B[33mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1720\u001B[39m     \u001B[43mxet_get\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1721\u001B[39m \u001B[43m        \u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1722\u001B[39m \u001B[43m        \u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1723\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1724\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1725\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdisplayed_filename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1726\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1727\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1728\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m xet_file_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m constants.HF_HUB_DISABLE_XET:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/5. Semester/LLM/rag_project/.venv/lib/python3.14/site-packages/huggingface_hub/file_download.py:626\u001B[39m, in \u001B[36mxet_get\u001B[39m\u001B[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001B[39m\n\u001B[32m    623\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mprogress_updater\u001B[39m(progress_bytes: \u001B[38;5;28mfloat\u001B[39m):\n\u001B[32m    624\u001B[39m     progress.update(progress_bytes)\n\u001B[32m--> \u001B[39m\u001B[32m626\u001B[39m \u001B[43mdownload_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m    \u001B[49m\u001B[43mxet_download_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    628\u001B[39m \u001B[43m    \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconnection_info\u001B[49m\u001B[43m.\u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    629\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken_info\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconnection_info\u001B[49m\u001B[43m.\u001B[49m\u001B[43maccess_token\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconnection_info\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexpiration_unix_epoch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    630\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken_refresher\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken_refresher\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    631\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprogress_updater\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mprogress_updater\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    632\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "ed48a64b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T13:46:45.068733Z",
     "start_time": "2025-11-05T13:46:45.065494Z"
    }
   },
   "source": [
    "# Funktion für semantische Suche, basierend auf Kosinus-Ähnlichkeit\n",
    "def semantic_search(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Performs semantic search using sentence-transformers built-in cosine similarity.\n",
    "    \n",
    "    Returns top_k documents and their similarity scores.\n",
    "    \"\"\"\n",
    "    # Embedding für die Query erzeugen\n",
    "    query_emb = model.encode(query, convert_to_tensor=True)\n",
    "    \n",
    "    # Kosinus-Ähnlichkeit zwischen Query und allen Dokumenten berechnen\n",
    "    cosine_scores = util.cos_sim(query_emb, doc_embeddings)  # shape: (1, num_docs)\n",
    "    \n",
    "    # Ranking der Dokumente, nach höchstem Ähnlichkeits-Score; begrenzt durch Parameter top_k\n",
    "    ranked_indices = cosine_scores[0].argsort(descending=True)[:top_k]\n",
    "    \n",
    "    # Rückgabe der ähnlichsten Dokumente\n",
    "    return [(int(idx), float(cosine_scores[0][idx])) for idx in ranked_indices]"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "584ca0d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T13:46:39.944704Z",
     "start_time": "2025-11-05T13:46:39.876868Z"
    }
   },
   "source": [
    "# Testen\n",
    "queries = ['bestellung', 'rückgabe', 'versand', 'shipping']\n",
    "\n",
    "for q in queries:\n",
    "    print(f'\\nQuery: {q}')\n",
    "    for idx, score in semantic_search(q):\n",
    "        print(f'  Score: {score:.3f} | Doc {idx}: {documents[idx]}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: bestellung\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m q \u001B[38;5;129;01min\u001B[39;00m queries:\n\u001B[32m      5\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mQuery: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mq\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m idx, score \u001B[38;5;129;01min\u001B[39;00m \u001B[43msemantic_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m      7\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33m  Score: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mscore\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m | Doc \u001B[39m\u001B[38;5;132;01m{\u001B[39;00midx\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdocuments[idx]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 9\u001B[39m, in \u001B[36msemantic_search\u001B[39m\u001B[34m(query, top_k)\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[33;03mPerforms semantic search using sentence-transformers built-in cosine similarity.\u001B[39;00m\n\u001B[32m      5\u001B[39m \n\u001B[32m      6\u001B[39m \u001B[33;03mReturns top_k documents and their similarity scores.\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Embedding für die Query erzeugen\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m query_emb = \u001B[43mmodel\u001B[49m.encode(query, convert_to_tensor=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m# Kosinus-Ähnlichkeit zwischen Query und allen Dokumenten berechnen\u001B[39;00m\n\u001B[32m     12\u001B[39m cosine_scores = util.cos_sim(query_emb, doc_embeddings)  \u001B[38;5;66;03m# shape: (1, num_docs)\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "d81c990b",
   "metadata": {},
   "source": [
    "## 4. Hausaufgabe: Ein vortrainiertes **Modell für deutschsprachige Dokumente** finden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5bcf64",
   "metadata": {},
   "source": [
    "Ihre Aufgabe ist es, ein vortrainiertes Modell zu finden, das sich für die semantische Suche auf Deutsch eignet. \n",
    "\n",
    "\n",
    "Hierfür haben Sie zwei Möglichkeiten: \n",
    "\n",
    "**Multilinguale Modelle:** Viele Modelle sind multilingual, z. B. distiluse-base-multilingual-cased-v2, welches Deutsch unterstützt. Multilinguale Modelle sind flexibel für viele Sprachen, eventuell mit leicht geringerer Genauigkeit für Deutsch.\n",
    "\n",
    "**Deutsch-spezifische Modelle:** Einige Modelle wurden speziell auf deutsche Texte feinjustiert. Deutsch-spezifische Modelle bieten oft eine höhere Genauigkeit für deutsche Texte, eignen sich aber nicht für andere Sprachen.\n",
    "\n",
    "### Schritt 1: Hugging Face Modelle durchsuchen\n",
    "\n",
    "- Besuchen Sie: https://huggingface.co/models\n",
    "\n",
    "- Verwenden Sie die Suchleiste mit Keywords wie z.B.:\n",
    "\n",
    "„german sentence-transformer“\n",
    "\n",
    "„multilingual sentence embeddings“\n",
    "- Alternativ können Sie auch den Filter der Suchfunktion verwenden, um auf die Library `sentence-transformers` und deutsche Sprache zu fokussieren. \n",
    "\n",
    "- Wählen Sie ein Modell aus. \n",
    "\n",
    "- Prüfen Sie die Beschreibung und stellen Sie sicher, dass Deutsch (`de`) unterstützt wird.\n",
    "\n",
    "\n",
    "### Schritt 2: Modell anwenden\n",
    "\n",
    "- Passen Sie den obigen Code so an, dass das von Ihnen ausgewählte Modell verwendet wird. \n",
    "\n",
    "- Probieren Sie einige Suchanfragen erneut aus. \n",
    "\n",
    "- Vergleichen Sie das Ergebnis mit der vorherigen Suche. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
